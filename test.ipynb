{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from model import HierAttModel\n",
    "import gensim\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from word_embeder import MyTokenizer\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## backgoud color control\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "def mk_weight_string(str_list, w_list):\n",
    "    temp_str = []\n",
    "    for string, weight in zip(str_list, w_list):\n",
    "        temp_str += ['<span style=\"background-color:rgba(255,0,0,' +str(weight)+ ');\">' + string + '</span>']\n",
    "    return \" \".join(temp_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_config_path = \"model/config.json\"\n",
    "word2vec_model_path = \"model/word2vec.model\"\n",
    "HAN_mdoel_path = \"model/1/model4.pwf\"\n",
    "HAN_config_path = \"model/1/config.json\"\n",
    "tokenizer_name = \"word_tokenizer\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load word2vec config\n",
    "with open(word2vec_config_path, 'r') as f:\n",
    "    word2vec_config = json.load(f)\n",
    "word2vec_config = Struct(**word2vec_config)\n",
    "\n",
    "##Load word2vec model\n",
    "word2vec_model = Word2Vec.load(word2vec_model_path)\n",
    "embedding = word2vec_model.wv.vectors\n",
    "dict_size = len(embedding)\n",
    "index2word = word2vec_model.wv.index2word\n",
    "word_vec_dim = word2vec_model.vector_size\n",
    "\n",
    "#Insert Unknown Token\n",
    "unknown_word = preprocessing.normalize(np.random.rand(1, word_vec_dim))\n",
    "embedding = torch.from_numpy(np.concatenate([unknown_word, embedding], axis=0).astype(np.float))\n",
    "index2word = ['[UNK]'] + index2word\n",
    "dict_size += 1\n",
    "word2index = {text : index for index, text in enumerate(index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load tokenizer\n",
    "tokenizer = MyTokenizer(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load HAN config\n",
    "with open(HAN_config_path, 'r') as f:\n",
    "    HAN_config = json.load(f)\n",
    "HAN_config = Struct(**HAN_config)\n",
    "\n",
    "##Load HAN model\n",
    "model = HierAttModel(input_size=dict_size,\n",
    "                     word_vec_dim=word_vec_dim,\n",
    "                     hidden_size=HAN_config.hidden_size,\n",
    "                     num_class=4,\n",
    "                     running_size=HAN_config.running_size,\n",
    "                     n_layers=HAN_config.n_layers,\n",
    "                     device=device\n",
    "                     ).to(device)\n",
    "model.set_embedding(embedding)\n",
    "check_point = torch.load(HAN_mdoel_path)\n",
    "model.load_state_dict(check_point[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=\"\"\"\n",
    "BERT is a method of pre-training language representations, meaning that we train a general-purpose \"language understanding\" model on a large text corpus (like Wikipedia), and then use that model for downstream NLP tasks that we care about (like question answering). BERT outperforms previous methods because it is the first unsupervised, deeply bidirectional system for pre-training NLP.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[word for word in\n",
    "                           tokenizer.tokenize(sentences, lemma=False)] for sentences in sent_tokenize(doc)]\n",
    "temp_index = [[word2index.get(word) if word2index.get(word) else 0 for word in\n",
    "                           tokenizer.tokenize(sentences)] for sentences in sent_tokenize(doc)]\n",
    "for sentence in temp_index:\n",
    "    ##Even though there is no word after preprocess procedure, must put something like \"[UNK]\" to run machine\n",
    "    if len(sentence) == 0:\n",
    "        sentence.extend([0])\n",
    "\n",
    "temp_sent_len = len(temp_index)\n",
    "temp_word_len = [len(sent) for sent in temp_index]\n",
    "\n",
    "max_sent_len = temp_sent_len\n",
    "max_word_len = max(temp_word_len)\n",
    "\n",
    "for sent in temp_index:\n",
    "    if len(sent) < max_word_len:\n",
    "        extended_words = [0 for _ in range(max_word_len - len(sent))]\n",
    "        sent.extend(extended_words)\n",
    "\n",
    "if len(temp_index) < max_sent_len:\n",
    "    extended_sentences = [[0 for _ in range(max_word_len)] for _ in\n",
    "                          range(max_sent_len - len(temp_index))]\n",
    "    temp_index.extend(extended_sentences)\n",
    "\n",
    "temp_index = [sentences[:max_word_len] for sentences in temp_index][:max_sent_len]\n",
    "\n",
    "if len(temp_word_len) < max_sent_len:\n",
    "    extended_word_len = [0 for _ in range(self.max_sent_len - len(temp_word_len))]\n",
    "    temp_word_len.extend(extended_word_len)\n",
    "temp_word_len = temp_word_len[:max_sent_len]\n",
    "\n",
    "temp_index = torch.tensor(temp_index)\n",
    "temp_sent_len = torch.tensor(temp_sent_len)\n",
    "temp_word_len = torch.tensor(temp_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "temp_index = temp_index.unsqueeze(0).to(device)\n",
    "temp_sent_len = temp_sent_len.unsqueeze(0).to(device)\n",
    "temp_word_len = temp_word_len.unsqueeze(0).to(device)\n",
    "y_hat, weights, sent_weights = model(temp_index, temp_sent_len, temp_word_len)\n",
    "ps = torch.exp(y_hat)\n",
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "weights = weights.tolist()\n",
    "print(top_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"background-color:rgba(255,0,0,0.013922115787863731);\">BERT</span> <span style=\"background-color:rgba(255,0,0,0.022177787497639656);\">is</span> <span style=\"background-color:rgba(255,0,0,0.022495588287711143);\">a</span> <span style=\"background-color:rgba(255,0,0,0.021066157147288322);\">method</span> <span style=\"background-color:rgba(255,0,0,0.019460387527942657);\">of</span> <span style=\"background-color:rgba(255,0,0,0.015218591317534447);\">pre-training</span> <span style=\"background-color:rgba(255,0,0,0.015542146749794483);\">language</span> <span style=\"background-color:rgba(255,0,0,0.014453896321356297);\">representations</span> <span style=\"background-color:rgba(255,0,0,0.020396994426846504);\">,</span> <span style=\"background-color:rgba(255,0,0,0.018746059387922287);\">meaning</span> <span style=\"background-color:rgba(255,0,0,0.023213043808937073);\">that</span> <span style=\"background-color:rgba(255,0,0,0.02284332923591137);\">we</span> <span style=\"background-color:rgba(255,0,0,0.018137194216251373);\">train</span> <span style=\"background-color:rgba(255,0,0,0.01934722438454628);\">a</span> <span style=\"background-color:rgba(255,0,0,0.01467967126518488);\">general-purpose</span> <span style=\"background-color:rgba(255,0,0,0.02086767368018627);\">``</span> <span style=\"background-color:rgba(255,0,0,0.01817169040441513);\">language</span> <span style=\"background-color:rgba(255,0,0,0.015617145225405693);\">understanding</span> <span style=\"background-color:rgba(255,0,0,0.01802458055317402);\">''</span> <span style=\"background-color:rgba(255,0,0,0.021063458174467087);\">model</span> <span style=\"background-color:rgba(255,0,0,0.01882774382829666);\">on</span> <span style=\"background-color:rgba(255,0,0,0.02261020615696907);\">a</span> <span style=\"background-color:rgba(255,0,0,0.022140467539429665);\">large</span> <span style=\"background-color:rgba(255,0,0,0.017904847860336304);\">text</span> <span style=\"background-color:rgba(255,0,0,0.013319865800440311);\">corpus</span> <span style=\"background-color:rgba(255,0,0,0.022732404991984367);\">(</span> <span style=\"background-color:rgba(255,0,0,0.024310944601893425);\">like</span> <span style=\"background-color:rgba(255,0,0,0.02019471861422062);\">Wikipedia</span> <span style=\"background-color:rgba(255,0,0,0.027495251968503);\">)</span> <span style=\"background-color:rgba(255,0,0,0.027174893766641617);\">,</span> <span style=\"background-color:rgba(255,0,0,0.025396117940545082);\">and</span> <span style=\"background-color:rgba(255,0,0,0.02264234609901905);\">then</span> <span style=\"background-color:rgba(255,0,0,0.02600013092160225);\">use</span> <span style=\"background-color:rgba(255,0,0,0.026192210614681244);\">that</span> <span style=\"background-color:rgba(255,0,0,0.024438904598355293);\">model</span> <span style=\"background-color:rgba(255,0,0,0.02153320610523224);\">for</span> <span style=\"background-color:rgba(255,0,0,0.016504479572176933);\">downstream</span> <span style=\"background-color:rgba(255,0,0,0.014806346036493778);\">NLP</span> <span style=\"background-color:rgba(255,0,0,0.01667374186217785);\">tasks</span> <span style=\"background-color:rgba(255,0,0,0.02145756408572197);\">that</span> <span style=\"background-color:rgba(255,0,0,0.020830722525715828);\">we</span> <span style=\"background-color:rgba(255,0,0,0.020226502791047096);\">care</span> <span style=\"background-color:rgba(255,0,0,0.01943289488554001);\">about</span> <span style=\"background-color:rgba(255,0,0,0.022003985941410065);\">(</span> <span style=\"background-color:rgba(255,0,0,0.024233434349298477);\">like</span> <span style=\"background-color:rgba(255,0,0,0.02220672369003296);\">question</span> <span style=\"background-color:rgba(255,0,0,0.014752235263586044);\">answering</span> <span style=\"background-color:rgba(255,0,0,0.025241073220968246);\">)</span> <span style=\"background-color:rgba(255,0,0,0.02327110804617405);\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"background-color:rgba(255,0,0,0.049713362008333206);\">BERT</span> <span style=\"background-color:rgba(255,0,0,0.051862701773643494);\">outperforms</span> <span style=\"background-color:rgba(255,0,0,0.05578713119029999);\">previous</span> <span style=\"background-color:rgba(255,0,0,0.056381069123744965);\">methods</span> <span style=\"background-color:rgba(255,0,0,0.061875294893980026);\">because</span> <span style=\"background-color:rgba(255,0,0,0.06484333425760269);\">it</span> <span style=\"background-color:rgba(255,0,0,0.0698554590344429);\">is</span> <span style=\"background-color:rgba(255,0,0,0.06352352350950241);\">the</span> <span style=\"background-color:rgba(255,0,0,0.05695470795035362);\">first</span> <span style=\"background-color:rgba(255,0,0,0.046802420169115067);\">unsupervised</span> <span style=\"background-color:rgba(255,0,0,0.059989552944898605);\">,</span> <span style=\"background-color:rgba(255,0,0,0.05552929267287254);\">deeply</span> <span style=\"background-color:rgba(255,0,0,0.04709845036268234);\">bidirectional</span> <span style=\"background-color:rgba(255,0,0,0.05561910942196846);\">system</span> <span style=\"background-color:rgba(255,0,0,0.054653946310281754);\">for</span> <span style=\"background-color:rgba(255,0,0,0.04529276117682457);\">pre-training</span> <span style=\"background-color:rgba(255,0,0,0.04206357151269913);\">NLP</span> <span style=\"background-color:rgba(255,0,0,0.06215429678559303);\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent, weight in zip(tokens, weights):\n",
    "    temp_str = mk_weight_string(sent, weight)\n",
    "    printmd(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"background-color: #FFFF00\">Marked text</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"background-color:rgba(255,0,0,0.5);\">Marked text</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Color Sample\n",
    "printmd('<span style=\"background-color: #FFFF00\">Marked text</span>')\n",
    "printmd('<span style=\"background-color:rgba(255,0,0,0.5);\">Marked text</span>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "printmd() got an unexpected keyword argument 'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-912d042f822a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**bold and blue**\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: printmd() got an unexpected keyword argument 'color'"
     ]
    }
   ],
   "source": [
    "printmd(\"**bold and blue**\", color=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
